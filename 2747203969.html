<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.1.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="一些使用pytorch的注意点">
<meta name="keywords" content="pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="pytoch_trick">
<meta property="og:url" content="https://guozhiyao.github.io/2747203969.html">
<meta property="og:site_name" content="LearningNote">
<meta property="og:description" content="一些使用pytorch的注意点">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-05-27T07:31:38.013Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="pytoch_trick">
<meta name="twitter:description" content="一些使用pytorch的注意点">





  
  
  <link rel="canonical" href="https://guozhiyao.github.io/2747203969">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>pytoch_trick | LearningNote</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LearningNote</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Notes</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://guozhiyao.github.io/2747203969.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GuoZhiyao">
      <meta itemprop="description" content="To recode the learning note">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LearningNote">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">pytoch_trick

              
            
          </h1>
        

        <div class="post-meta">
			
			  
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-14 12:24:53" itemprop="dateCreated datePublished" datetime="2019-05-14T12:24:53Z">2019-05-14</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-27 07:31:38" itemprop="dateModified" datetime="2019-05-27T07:31:38Z">2019-05-27</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习框架/" itemprop="url" rel="index"><span itemprop="name">深度学习框架</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习框架/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习框架/pytorch/技巧/" itemprop="url" rel="index"><span itemprop="name">技巧</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2747203969.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2747203969.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2747203969.html" class="leancloud_visitors" data-flag-title="pytoch_trick">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">7.5k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">7 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>一些使用pytorch的注意点<br><a id="more"></a></p>
<h1 id="小点"><a href="#小点" class="headerlink" title="小点"></a>小点</h1><ol>
<li>如果在<code>__init__()</code>中使用for循环定义网络结构时，比如<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">m</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, output_dims)</span>:</span></span><br><span class="line">		self.linear = [torch.nn.Linear(input_dim, i) <span class="keyword">for</span> i <span class="keyword">in</span> output_dims]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如果在训练时候，直接使用<code>to(&#39;cuda:0&#39;)</code>，可能保存为list的参数无法导入到GPU上，使得参数分布在不同的device，所以需要加上<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">m</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, output_dims)</span>:</span></span><br><span class="line">		device = torch.device(<span class="string">'cuda:0'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">		self.linear = [torch.nn.Linear(input_dim, i).to(device) <span class="keyword">for</span> i <span class="keyword">in</span> output_dims]</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li>对于维度数目大于2的特征图交换维度时，要使用permute，transpose只适用于二维特征图。</li>
<li>使用DataLoader载入数据时，通常在一个epoch的最后一部分的数据无法构成一个完整的batch，我在这也经常快跑完一个epoch时候就报错，说维度不正确。<br>比较暴力的方法是设置<code>DataLoader</code>里面的<code>drop_last=True</code>，这样最后一部分数据就会丢掉，因为设置了<code>shuffle=True</code>，所以每次丢掉的样本也不相同。</li>
</ol>
<h1 id="加载预训练模型"><a href="#加载预训练模型" class="headerlink" title="加载预训练模型"></a>加载预训练模型</h1><p>pytorch中已经封装了一系列预训练好的模型，可以使用以下语句导入模型结构，并且设置<code>pretrained=True</code>来导入预训练模型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="comment">#resnet</span></span><br><span class="line">model = models.resnet152(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#desnet</span></span><br><span class="line">model = models.desnet121(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果还需要在这个模型基础上进行操作，还需要以下步骤</p>
<h2 id="冻结网络"><a href="#冻结网络" class="headerlink" title="冻结网络"></a>冻结网络</h2><p>冻结网络，需要将参数的<code>requires_grad</code>属性设置为<code>False</code>，可以使用以下方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">	param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>上面代码中，先使用<code>model.parameters()</code>获得模型所有的参数，然后设置所有参数都不需要梯度。<br>如果需要根据特定层来冻结参数，可以使用以下方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">trainable_variables = [] <span class="comment">#自己设置想要训练的参数名</span></span><br><span class="line"><span class="keyword">for</span> name,param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">	<span class="keyword">if</span> name <span class="keyword">in</span> trainable_variables:</span><br><span class="line">		param.requires_grad = <span class="literal">True</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>并且还需要修改优化器，使其只训练可训练的参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line">optimizer = optim.Adam(filter(<span class="keyword">lambda</span> p: p.requires_grad,model.parameters()),</span><br><span class="line">	lr = cfg.TRAIN.LR)</span><br></pre></td></tr></table></figure></p>
<p>其中，使用<code>filter</code>函数挑选出可训练参数。</p>
<p><strong>注意：</strong><br>在pytorch中，获取模型参数的方法主要有三种：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.parameters()</span><br><span class="line">model.named_parameters()</span><br><span class="line">model.state_dict()</span><br></pre></td></tr></table></figure></p>
<ol>
<li><code>parameters()</code>，可以迭代访问模型的参数，但是只会返回模型的所有参数，无法指定该参数是什么。</li>
<li><code>named_parameters()</code>，可以迭代访问模型的参数和参数名，可以根据参数名修改来对参数进行操作。<br>以上两种方法都可以用来更改参数的<code>requires_grad</code>属性，设置参数是否为可训练的。</li>
<li><code>state_dict()</code>，是字典形式，可以用<code>state_dict().items()</code>迭代访问参数名和对应的参数，但是在这里参数的<code>requires_grad</code>都为<code>False</code>。</li>
</ol>
<p><strong>参考：</strong><br><a href="https://blog.csdn.net/u013548568/article/details/84311099" target="_blank" rel="noopener">pytorch model.named_parameters() ,model.parameters() ,model.state_dict().items()</a></p>
<h2 id="调整网络结构后导入预训练模型"><a href="#调整网络结构后导入预训练模型" class="headerlink" title="调整网络结构后导入预训练模型"></a>调整网络结构后导入预训练模型</h2><p>当你修改了模型后，想要导入预训练模型，可能会出现参数维度不相同的错误，可以使用以下方法导入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_pretrained_model</span><span class="params">(pretrained_state_dict, model)</span>:</span></span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	pretrained_state_dict: 预训练的模型</span></span><br><span class="line"><span class="string">	model: 自己的模型</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	model_state = model.state_dict()</span><br><span class="line">	filter_state_dict = &#123;&#125;	<span class="comment">#保存筛选后的state_dict</span></span><br><span class="line">	new_k = []	<span class="comment">#保存model与pretrained_state_dict不符合的参数名</span></span><br><span class="line">	<span class="keyword">for</span> k,v <span class="keyword">in</span> pretrained_state_dict.items():</span><br><span class="line">		<span class="comment">#如果预训练的state_dict中的参数存在于模型中，并且两者的维度相同，才会用预训练的参数初始化模型的参数，否则就将其保存在new_k中</span></span><br><span class="line">		<span class="keyword">if</span> k <span class="keyword">in</span> model_state <span class="keyword">and</span> pretrained_state_dict[k].size()==model_state[k].size():</span><br><span class="line">			filter_state_dict[k]=v</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			new_k.append(k)</span><br><span class="line">	</span><br><span class="line">	model_state.update(filter_state_dict)	<span class="comment">#使用筛选后的state_dict更新</span></span><br><span class="line">	model.load_state_dict(model_state)	<span class="comment">#载入预训练参数</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">#对于不包含在预训练参数中的参数，使其可以学习，其余的冻结起来</span></span><br><span class="line">	<span class="keyword">for</span> name,param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">		<span class="keyword">if</span> name <span class="keyword">in</span> new_k:</span><br><span class="line">			param.requires_grad = <span class="literal">True</span></span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			param.requires_grad = <span class="literal">False</span></span><br><span class="line">	<span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<h1 id="查看模型结构"><a href="#查看模型结构" class="headerlink" title="查看模型结构"></a>查看模型结构</h1><p>使用的是第三方工具torchsummary，可以用以下命令下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Bond-SYSU/pytorch-summary</span><br></pre></td></tr></table></figure></p>
<p>使用方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br><span class="line">summary(your_model, input_size=(C,H,W))</span><br></pre></td></tr></table></figure></p>
<p>得到的就类似Keras的结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">----------------------------------------------------------------</span><br><span class="line">        Layer (type)               Output Shape         Param #</span><br><span class="line">================================================================</span><br><span class="line">            Conv2d-1           [-1, 10, 24, 24]             260</span><br><span class="line">            Conv2d-2             [-1, 20, 8, 8]           5,020</span><br><span class="line">         Dropout2d-3             [-1, 20, 8, 8]               0</span><br><span class="line">            Linear-4                   [-1, 50]          16,050</span><br><span class="line">            Linear-5                   [-1, 10]             510</span><br><span class="line">================================================================</span><br><span class="line">Total params: 21,840</span><br><span class="line">Trainable params: 21,840</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.00</span><br><span class="line">Forward/backward pass size (MB): 0.06</span><br><span class="line">Params size (MB): 0.08</span><br><span class="line">Estimated Total Size (MB): 0.15</span><br><span class="line">----------------------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<p><strong>参考：</strong><br><a href="https://github.com/sksq96/pytorch-summary" target="_blank" rel="noopener">pytorch-summary</a></p>
<h1 id="提取计算中间的特征图"><a href="#提取计算中间的特征图" class="headerlink" title="提取计算中间的特征图"></a>提取计算中间的特征图</h1><p>当我们使用封装好的模型去提取中间的特征图时，由于pytorch会自动舍弃图计算的中间结果，所以想要获取这些数值就需要使用钩子函数，包含对于Variable的钩子函数和对Module的钩子函数，这里主要说对于Module的。<br>对于Module的钩子函数，主要包含两种，一个是<code>register_forward_hook</code>和<code>register_backward_hook</code>，显而易见，第一个是用来钩取前向传播时候的特征图，第二个是用来钩取反向传播的梯度。</p>
<p><code>register_forward_hook</code>：具有以下形式<code>hook(module, input, output)-&gt;None</code>，这里的<code>module</code>就是你钩取的模块，<code>input</code>就是这个模块对应的输入特征图，<code>output</code>就是模块对应的输出特征图。<br><code>register_backward_hook</code>：具有以下形式<code>hook(module, grad_input, grad_output)-&gt;Tensor or None</code>。</p>
<p><strong>注意：</strong>钩子函数不应修改输入和输出，并且在使用后应及时删除，以避免每次都运行钩子增加运行负载。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>比如你使用预训练好的Resnet201<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line">model = models.resnet201(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>此时假设你要做对于输入图像的attention，就需要提取其中<code>14*14</code>的特征图，通过使用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br><span class="line">model.cuda()</span><br><span class="line">summary(model,(<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>))</span><br></pre></td></tr></table></figure></p>
<p>可以查看到各层的特征图大小，可以发现这个特征图是<code>&#39;RELU-483</code>的输出，并且通过查看<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.children()</span><br></pre></td></tr></table></figure></p>
<p>可以知道该特征图是对应<code>model.layer3</code>的输出，此时，我们就可以用钩子函数来钩取这个的输出，以下为代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Temp</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		super(Temp,self).__init__()</span><br><span class="line">		self.resnet = models.resnet152(pretrained=<span class="literal">True</span>)</span><br><span class="line">		self.handler = self.resnet.layer3.register_forward_hook(self.hook)</span><br><span class="line">		self.pick = <span class="literal">None</span></span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">hook</span><span class="params">(self, module, inputdata, output)</span>:</span></span><br><span class="line">		self.pick = output</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, images)</span></span></span><br><span class="line">		features = self.resnet(images)</span><br><span class="line">		self.handler.remove()</span><br><span class="line">		<span class="keyword">return</span> self.pick</span><br></pre></td></tr></table></figure></p>
<ol>
<li>首先对于你要钩取的模块，使用<code>register_forward_hook()</code>方法，并且传入自己写的钩取函数<code>hook()</code>用来指定对于钩取到的模块的操作</li>
<li>我这里的<code>hook()</code>函数就是将钩取的模块的输出保存到<code>self.pick</code>中，然后直接通过调用<code>self.pick</code>就能得到想要的特征图。</li>
<li>注意钩取完后要调用<code>remove()</code>将其删除，以避免每次都运行钩子增加运行负载。</li>
</ol>
<p><strong>问题：</strong><br>对于用<code>nn.Sequential()</code>封住的模块，不知道要怎么设置钩子函数。</p>
<p><strong>参考：</strong><br><a href="https://www.cnblogs.com/hellcat/p/8512090.html" target="_blank" rel="noopener">『PyTorch』第十六弹_hook技术</a></p>
<h1 id="实验结果可重复性"><a href="#实验结果可重复性" class="headerlink" title="实验结果可重复性"></a>实验结果可重复性</h1><p>模型训练时候，里面会含有大量的随机数，每次训练相同的模型，也可能因为随机数的不同和而是结果略有差异，就无法知道模型效果是否有提升，所以需要固定模型的随机数，使得实验结果可复现。</p>
<h2 id="CUDNN"><a href="#CUDNN" class="headerlink" title="CUDNN"></a>CUDNN</h2><p>cudnn中对卷积操作进行了优化，牺牲了精度来换取计算效率。如果需要保证可重复性，可以使用如下设置:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.backends <span class="keyword">import</span> cudnn</span><br><span class="line">cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure></p>
<p>当设置<code>cudnn.backends=True</code>，则让内置的cudnn的auto-tuner自动寻找最合适当前配置的高效算法，来达到优化运行效率的问题，①如果网络的输入数据维度或类型变化不到时可以使用；②如果网络的输入数据在每次迭代都变化时，会导致cudnn每次都去寻找依次最优配置，范围降低运行效率。(<a href="https://www.pytorchtutorial.com/when-should-we-set-cudnn-benchmark-to-true/" target="_blank" rel="noopener">参考</a> )<br>当设置<code>cudnn.deterministic = True</code>时，会确保实验可重复性。<br>不过实际上这个设置对精度影响不大，仅仅是小数点后几位的差别。所以如果不是对精度要求极高，其实不太建议修改，因为会使计算效率降低。</p>
<h2 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(seed)            <span class="comment"># 为CPU设置随机种子</span></span><br><span class="line">torch.cuda.manual_seed(seed)       <span class="comment"># 为当前GPU设置随机种子</span></span><br><span class="line">torch.cuda.manual_seed_all(seed)   <span class="comment"># 为所有GPU设置随机种子</span></span><br></pre></td></tr></table></figure>
<h2 id="python-amp-numpy"><a href="#python-amp-numpy" class="headerlink" title="python &amp; numpy"></a>python &amp; numpy</h2><p>如果读取数据的过程采用了随机预处理(如RandomCrop、RandomHorizontalFlip等)，那么对python、numpy的随机数生成器也需要设置种子。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br></pre></td></tr></table></figure></p>
<h2 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h2><p>注意，如果dataloader采用了多线程(num_workers &gt; 1), 那么由于读取数据的顺序不同，最终运行结果也会有差异。也就是说，改变num_workers参数，也会对实验结果产生影响。目前暂时没有发现解决这个问题的方法，但是只要固定num_workers数目（线程数）不变，基本上也能够重复实验结果。</p>
<p>对于不同线程的随机数种子设置，主要通过DataLoader的worker_init_fn参数来实现。默认情况下使用线程ID作为随机数种子。如果需要自己设定，可以参考以下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">GLOBAL_SEED = <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_seed</span><span class="params">(seed)</span>:</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line"> </span><br><span class="line">GLOBAL_WORKER_ID = <span class="literal">None</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">worker_init_fn</span><span class="params">(worker_id)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> GLOBAL_WORKER_ID</span><br><span class="line">    GLOBAL_WORKER_ID = worker_id</span><br><span class="line">    set_seed(GLOBAL_SEED + worker_id)</span><br><span class="line"> </span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">16</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>, worker_init_fn=worker_init_fn)</span><br></pre></td></tr></table></figure></p>
<h2 id="设置位置"><a href="#设置位置" class="headerlink" title="设置位置"></a>设置位置</h2><p>为了保证能将整个模型的随机数都固定住，需要在你的train.py的前几行设置这些FLAG，然后再import模型的其他部分。<br><strong>参考：</strong><br><a href="https://blog.csdn.net/hyk_1996/article/details/84307108" target="_blank" rel="noopener">PyTorch的可重复性问题 （如何使实验结果可复现）</a><br><a href="https://blog.csdn.net/qq_16234613/article/details/81356876" target="_blank" rel="noopener">关于随机种子random.seed()测试 pytorch完全设置随机种子</a><br><strong>其他：</strong><br>可能还有其他设置了<code>cudnn.deterministic = True</code>时还是无法复现实验，可以参考<a href="https://link.zhihu.com/?target=https%3A//github.com/pytorch/pytorch/issues/12207%23issuecomment-425746601" target="_blank" rel="noopener">这里</a> 。</p>
<h1 id="children与modeules的区别"><a href="#children与modeules的区别" class="headerlink" title="children与modeules的区别"></a>children与modeules的区别</h1><p>占坑<br><strong>参考：</strong><br><a href="https://blog.csdn.net/lxx516/article/details/79016980" target="_blank" rel="noopener">pytorch Module里的children()与modules()的区别</a></p>
<h1 id="pack-padded-sequence和pad-packed-sequence"><a href="#pack-padded-sequence和pad-packed-sequence" class="headerlink" title="pack_padded_sequence和pad_packed_sequence"></a>pack_padded_sequence和pad_packed_sequence</h1><p>占坑<br><strong>参考：</strong><br><a href="https://blog.csdn.net/lssc4205/article/details/79474735" target="_blank" rel="noopener">pytorch里的pack_padded_sequence和pad_packed_sequence解析</a><br><a href="https://zhuanlan.zhihu.com/p/59772104" target="_blank" rel="noopener">PyTorch 训练 RNN 时，序列长度不固定怎么办？</a></p>
<h1 id="好东西"><a href="#好东西" class="headerlink" title="好东西"></a>好东西</h1><p><a href="https://zhuanlan.zhihu.com/p/39752167" target="_blank" rel="noopener">Pytorch 提速指南</a><br><a href="https://oldpan.me/archives/how-to-use-memory-pytorch" target="_blank" rel="noopener">牺牲速度降低显存</a></p>
<h1 id="使用GPU"><a href="#使用GPU" class="headerlink" title="使用GPU"></a>使用GPU</h1><p>之前使用pytorch时候，根据我的显卡版本在官网上选择了conda的安装指令<br><code>conda install pytorch torchvision cudatoolkit=8.0 -c pytorch</code><br>但是安装后，显示的<code>torch.cuda.is_available</code>总是False，也尝试降低<code>cudatoolkit</code>的版本，也是不行，最终找到问题是没有在<code>~/.bashrc</code>中配置cuda环境，贼搞笑。<br>配置的详细过程可以参考下面的连接。<br><strong>参考：</strong><br><a href="https://blog.csdn.net/yimingsilence/article/details/79631567" target="_blank" rel="noopener">使用GPU</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/pytorch/" rel="tag"># pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2093499392.html" rel="next" title="leetcode_713：乘积小于K的子数组">
                <i class="fa fa-chevron-left"></i> leetcode_713：乘积小于K的子数组
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/74708972.html" rel="prev" title="免费使用google的GPU">
                免费使用google的GPU <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">GuoZhiyao</p>
              <div class="site-description motion-element" itemprop="description">To recode the learning note</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">17</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">15</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#小点"><span class="nav-number">1.</span> <span class="nav-text">小点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#加载预训练模型"><span class="nav-number">2.</span> <span class="nav-text">加载预训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#冻结网络"><span class="nav-number">2.1.</span> <span class="nav-text">冻结网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#调整网络结构后导入预训练模型"><span class="nav-number">2.2.</span> <span class="nav-text">调整网络结构后导入预训练模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#查看模型结构"><span class="nav-number">3.</span> <span class="nav-text">查看模型结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#提取计算中间的特征图"><span class="nav-number">4.</span> <span class="nav-text">提取计算中间的特征图</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用"><span class="nav-number">4.1.</span> <span class="nav-text">使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验结果可重复性"><span class="nav-number">5.</span> <span class="nav-text">实验结果可重复性</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDNN"><span class="nav-number">5.1.</span> <span class="nav-text">CUDNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch"><span class="nav-number">5.2.</span> <span class="nav-text">pytorch</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python-amp-numpy"><span class="nav-number">5.3.</span> <span class="nav-text">python &amp; numpy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dataloader"><span class="nav-number">5.4.</span> <span class="nav-text">dataloader</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设置位置"><span class="nav-number">5.5.</span> <span class="nav-text">设置位置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#children与modeules的区别"><span class="nav-number">6.</span> <span class="nav-text">children与modeules的区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pack-padded-sequence和pad-packed-sequence"><span class="nav-number">7.</span> <span class="nav-text">pack_padded_sequence和pad_packed_sequence</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#好东西"><span class="nav-number">8.</span> <span class="nav-text">好东西</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用GPU"><span class="nav-number">9.</span> <span class="nav-text">使用GPU</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">GuoZhiyao</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">81k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">1:14</span>
  
</div>









        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  

  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.1"></script>

  <script src="/js/motion.js?v=7.1.1"></script>



  
  


  <script src="/js/affix.js?v=7.1.1"></script>

  <script src="/js/schemes/pisces.js?v=7.1.1"></script>



  
  <script src="/js/scrollspy.js?v=7.1.1"></script>
<script src="/js/post-details.js?v=7.1.1"></script>



  


  <script src="/js/next-boot.js?v=7.1.1"></script>


  

  

  

  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: true,
    appId: 'JUzzK5xpdFaEXELmjt5SEQRy-gzGzoHsz',
    appKey: 'WCtWmzBiyev0hUF8afIuLCuh',
    placeholder: 'Just go go',
    avatar: 'wavatar',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn'
  });
</script>




  


  




  
  
  <script>
    
    function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .done(function() {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.time + 1);
              })
            
              .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
              })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1 }))
                .done(function() {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function() {
                  console.log('Failed to create');
                });
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log('LeanCloud Counter Error: ' + responseJSON.code + ' ' + responseJSON.error);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'LokSnuG7d5scPcPdaIQi5rgJ-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'LokSnuG7d5scPcPdaIQi5rgJ-gzGzoHsz',
                'X-LC-Key': 'hlcodrMmu7eeKpdvsymRe7Vk',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            addCount(Counter);
          
        });
    });
  </script>



  

  
  

  
  

  


  

  

  

  

  

  

  

  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
